{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization, Activation\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "val_data = pd.read_csv('val.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "lengthTestData = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text data for preprocessing\n",
    "text = pd.concat([train_data['text'], val_data['text']], ignore_index=True)\n",
    "text_test = test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_features = train_data.iloc[:,-31:]\n",
    "val_linguistic_features = val_data.iloc[:,-31:]\n",
    "test_linguistic_features = test_data.iloc[:,-31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words_per_Sentence</th>\n",
       "      <th>Percentage_First_Person_Singular</th>\n",
       "      <th>Percentage_Third_Person</th>\n",
       "      <th>Percentage_Exclusive</th>\n",
       "      <th>Percentage_Negation</th>\n",
       "      <th>Percentage_Causation</th>\n",
       "      <th>Percentage_Sense</th>\n",
       "      <th>Percentage_PositiveEmo</th>\n",
       "      <th>Percentage_NegativeEmo</th>\n",
       "      <th>Percentage_AffectiveTerms</th>\n",
       "      <th>...</th>\n",
       "      <th>Percentage_PastVerb</th>\n",
       "      <th>Percentage_PresentVerb</th>\n",
       "      <th>Percentage_FutureVerb</th>\n",
       "      <th>Percentage_Article</th>\n",
       "      <th>Percentage_Pronoun</th>\n",
       "      <th>Percentage_Conjunction</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Emotiveness</th>\n",
       "      <th>Rate_of_Adjectives_Adverbs</th>\n",
       "      <th>Flesch_Kincaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.930502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>5.405405</td>\n",
       "      <td>3.474903</td>\n",
       "      <td>3.474903</td>\n",
       "      <td>6.949807</td>\n",
       "      <td>...</td>\n",
       "      <td>3.861004</td>\n",
       "      <td>4.633205</td>\n",
       "      <td>0.772201</td>\n",
       "      <td>5.019305</td>\n",
       "      <td>4.247104</td>\n",
       "      <td>5.405405</td>\n",
       "      <td>0.548263</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.735562</td>\n",
       "      <td>1.519757</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>1.519757</td>\n",
       "      <td>4.863222</td>\n",
       "      <td>2.735562</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>3.343465</td>\n",
       "      <td>...</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>0.911854</td>\n",
       "      <td>7.294833</td>\n",
       "      <td>5.471125</td>\n",
       "      <td>5.167173</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.191781</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>1.095890</td>\n",
       "      <td>6.027397</td>\n",
       "      <td>3.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.013699</td>\n",
       "      <td>...</td>\n",
       "      <td>3.835616</td>\n",
       "      <td>3.013699</td>\n",
       "      <td>1.095890</td>\n",
       "      <td>8.219178</td>\n",
       "      <td>4.931507</td>\n",
       "      <td>3.561644</td>\n",
       "      <td>0.495890</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.254545</td>\n",
       "      <td>0.085543</td>\n",
       "      <td>4.790419</td>\n",
       "      <td>1.710864</td>\n",
       "      <td>1.197605</td>\n",
       "      <td>2.138580</td>\n",
       "      <td>3.079555</td>\n",
       "      <td>2.053037</td>\n",
       "      <td>1.796407</td>\n",
       "      <td>3.849444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138580</td>\n",
       "      <td>4.790419</td>\n",
       "      <td>0.427716</td>\n",
       "      <td>6.843456</td>\n",
       "      <td>8.297690</td>\n",
       "      <td>5.560308</td>\n",
       "      <td>0.437981</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.273171</td>\n",
       "      <td>0.101818</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48634</th>\n",
       "      <td>17.466667</td>\n",
       "      <td>1.908397</td>\n",
       "      <td>3.053435</td>\n",
       "      <td>1.145038</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>3.053435</td>\n",
       "      <td>3.053435</td>\n",
       "      <td>3.053435</td>\n",
       "      <td>6.106870</td>\n",
       "      <td>...</td>\n",
       "      <td>4.961832</td>\n",
       "      <td>8.015267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.580153</td>\n",
       "      <td>17.557252</td>\n",
       "      <td>3.816794</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.118321</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48635</th>\n",
       "      <td>23.500000</td>\n",
       "      <td>3.723404</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>4.255319</td>\n",
       "      <td>5.851064</td>\n",
       "      <td>10.106383</td>\n",
       "      <td>...</td>\n",
       "      <td>6.382979</td>\n",
       "      <td>6.382979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.382979</td>\n",
       "      <td>9.574468</td>\n",
       "      <td>4.787234</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48636</th>\n",
       "      <td>25.785714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.908587</td>\n",
       "      <td>1.800554</td>\n",
       "      <td>0.415512</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.831025</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>2.216066</td>\n",
       "      <td>3.462604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800554</td>\n",
       "      <td>5.955679</td>\n",
       "      <td>0.831025</td>\n",
       "      <td>7.063712</td>\n",
       "      <td>5.678670</td>\n",
       "      <td>5.401662</td>\n",
       "      <td>0.488920</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48637</th>\n",
       "      <td>26.809524</td>\n",
       "      <td>0.532860</td>\n",
       "      <td>8.703375</td>\n",
       "      <td>1.598579</td>\n",
       "      <td>0.355240</td>\n",
       "      <td>1.598579</td>\n",
       "      <td>2.131439</td>\n",
       "      <td>2.131439</td>\n",
       "      <td>4.085258</td>\n",
       "      <td>6.216696</td>\n",
       "      <td>...</td>\n",
       "      <td>3.552398</td>\n",
       "      <td>5.506217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.440497</td>\n",
       "      <td>13.499112</td>\n",
       "      <td>5.150977</td>\n",
       "      <td>0.488455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.110124</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48638</th>\n",
       "      <td>29.176471</td>\n",
       "      <td>1.814516</td>\n",
       "      <td>4.032258</td>\n",
       "      <td>2.217742</td>\n",
       "      <td>1.008065</td>\n",
       "      <td>1.209677</td>\n",
       "      <td>2.016129</td>\n",
       "      <td>2.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>3.830645</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217742</td>\n",
       "      <td>4.233871</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>7.056452</td>\n",
       "      <td>13.508065</td>\n",
       "      <td>6.653226</td>\n",
       "      <td>0.497984</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.120968</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48639 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words_per_Sentence  Percentage_First_Person_Singular  \\\n",
       "0               28.777778                          0.000000   \n",
       "1               32.900000                          0.000000   \n",
       "2               30.416667                          0.000000   \n",
       "3               21.254545                          0.085543   \n",
       "4               24.444444                          0.000000   \n",
       "...                   ...                               ...   \n",
       "48634           17.466667                          1.908397   \n",
       "48635           23.500000                          3.723404   \n",
       "48636           25.785714                          0.000000   \n",
       "48637           26.809524                          0.532860   \n",
       "48638           29.176471                          1.814516   \n",
       "\n",
       "       Percentage_Third_Person  Percentage_Exclusive  Percentage_Negation  \\\n",
       "0                     1.930502              0.000000             0.000000   \n",
       "1                     2.735562              1.519757             0.607903   \n",
       "2                     2.191781              0.821918             0.547945   \n",
       "3                     4.790419              1.710864             1.197605   \n",
       "4                     3.181818              1.636364             0.545455   \n",
       "...                        ...                   ...                  ...   \n",
       "48634                 3.053435              1.145038             0.381679   \n",
       "48635                 1.063830              0.531915             0.531915   \n",
       "48636                 2.908587              1.800554             0.415512   \n",
       "48637                 8.703375              1.598579             0.355240   \n",
       "48638                 4.032258              2.217742             1.008065   \n",
       "\n",
       "       Percentage_Causation  Percentage_Sense  Percentage_PositiveEmo  \\\n",
       "0                  2.702703          5.405405                3.474903   \n",
       "1                  1.519757          4.863222                2.735562   \n",
       "2                  1.095890          6.027397                3.013699   \n",
       "3                  2.138580          3.079555                2.053037   \n",
       "4                  2.181818          6.181818                3.545455   \n",
       "...                     ...               ...                     ...   \n",
       "48634              0.381679          3.053435                3.053435   \n",
       "48635              1.063830          1.063830                4.255319   \n",
       "48636              0.969529          0.831025                0.969529   \n",
       "48637              1.598579          2.131439                2.131439   \n",
       "48638              1.209677          2.016129                2.822581   \n",
       "\n",
       "       Percentage_NegativeEmo  Percentage_AffectiveTerms  ...  \\\n",
       "0                    3.474903                   6.949807  ...   \n",
       "1                    0.607903                   3.343465  ...   \n",
       "2                    0.000000                   3.013699  ...   \n",
       "3                    1.796407                   3.849444  ...   \n",
       "4                    1.727273                   5.272727  ...   \n",
       "...                       ...                        ...  ...   \n",
       "48634                3.053435                   6.106870  ...   \n",
       "48635                5.851064                  10.106383  ...   \n",
       "48636                2.216066                   3.462604  ...   \n",
       "48637                4.085258                   6.216696  ...   \n",
       "48638                0.806452                   3.830645  ...   \n",
       "\n",
       "       Percentage_PastVerb  Percentage_PresentVerb  Percentage_FutureVerb  \\\n",
       "0                 3.861004                4.633205               0.772201   \n",
       "1                 2.127660                2.127660               0.911854   \n",
       "2                 3.835616                3.013699               1.095890   \n",
       "3                 2.138580                4.790419               0.427716   \n",
       "4                 2.818182                5.818182               0.818182   \n",
       "...                    ...                     ...                    ...   \n",
       "48634             4.961832                8.015267               0.000000   \n",
       "48635             6.382979                6.382979               0.000000   \n",
       "48636             1.800554                5.955679               0.831025   \n",
       "48637             3.552398                5.506217               0.000000   \n",
       "48638             2.217742                4.233871               1.612903   \n",
       "\n",
       "       Percentage_Article  Percentage_Pronoun  Percentage_Conjunction  \\\n",
       "0                5.019305            4.247104                5.405405   \n",
       "1                7.294833            5.471125                5.167173   \n",
       "2                8.219178            4.931507                3.561644   \n",
       "3                6.843456            8.297690                5.560308   \n",
       "4                9.000000            5.909091                4.727273   \n",
       "...                   ...                 ...                     ...   \n",
       "48634            4.580153           17.557252                3.816794   \n",
       "48635            6.382979            9.574468                4.787234   \n",
       "48636            7.063712            5.678670                5.401662   \n",
       "48637            4.440497           13.499112                5.150977   \n",
       "48638            7.056452           13.508065                6.653226   \n",
       "\n",
       "       Lexical_Diversity  Emotiveness  Rate_of_Adjectives_Adverbs  \\\n",
       "0               0.548263     0.247059                    0.081081   \n",
       "1               0.595745     0.296610                    0.106383   \n",
       "2               0.495890     0.246479                    0.095890   \n",
       "3               0.437981     0.415254                    0.125749   \n",
       "4               0.440000     0.273171                    0.101818   \n",
       "...                  ...          ...                         ...   \n",
       "48634           0.553435     0.392405                    0.118321   \n",
       "48635           0.505319     0.357143                    0.132979   \n",
       "48636           0.488920     0.283636                    0.108033   \n",
       "48637           0.488455     0.333333                    0.110124   \n",
       "48638           0.497984     0.397351                    0.120968   \n",
       "\n",
       "       Flesch_Kincaid  \n",
       "0                14.1  \n",
       "1                13.5  \n",
       "2                11.8  \n",
       "3                 9.9  \n",
       "4                10.8  \n",
       "...               ...  \n",
       "48634             8.4  \n",
       "48635             8.4  \n",
       "48636            12.8  \n",
       "48637             9.8  \n",
       "48638            12.2  \n",
       "\n",
       "[48639 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linguistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words_per_Sentence</th>\n",
       "      <th>Percentage_First_Person_Singular</th>\n",
       "      <th>Percentage_Third_Person</th>\n",
       "      <th>Percentage_Exclusive</th>\n",
       "      <th>Percentage_Negation</th>\n",
       "      <th>Percentage_Causation</th>\n",
       "      <th>Percentage_Sense</th>\n",
       "      <th>Percentage_PositiveEmo</th>\n",
       "      <th>Percentage_NegativeEmo</th>\n",
       "      <th>Percentage_AffectiveTerms</th>\n",
       "      <th>...</th>\n",
       "      <th>Percentage_PastVerb</th>\n",
       "      <th>Percentage_PresentVerb</th>\n",
       "      <th>Percentage_FutureVerb</th>\n",
       "      <th>Percentage_Article</th>\n",
       "      <th>Percentage_Pronoun</th>\n",
       "      <th>Percentage_Conjunction</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Emotiveness</th>\n",
       "      <th>Rate_of_Adjectives_Adverbs</th>\n",
       "      <th>Flesch_Kincaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.078522</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.078522</td>\n",
       "      <td>1.154734</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>2.540416</td>\n",
       "      <td>2.771363</td>\n",
       "      <td>...</td>\n",
       "      <td>2.078522</td>\n",
       "      <td>2.078522</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>11.316397</td>\n",
       "      <td>6.004619</td>\n",
       "      <td>3.233256</td>\n",
       "      <td>0.496536</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.129330</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.666667</td>\n",
       "      <td>5.319149</td>\n",
       "      <td>5.851064</td>\n",
       "      <td>1.595745</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.659574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.659574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.595745</td>\n",
       "      <td>3.191489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.851064</td>\n",
       "      <td>13.829787</td>\n",
       "      <td>2.659574</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.122340</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.709677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.958225</td>\n",
       "      <td>2.349869</td>\n",
       "      <td>1.174935</td>\n",
       "      <td>1.044386</td>\n",
       "      <td>6.527415</td>\n",
       "      <td>2.480418</td>\n",
       "      <td>0.783290</td>\n",
       "      <td>3.394256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.916449</td>\n",
       "      <td>4.569191</td>\n",
       "      <td>1.436031</td>\n",
       "      <td>8.746736</td>\n",
       "      <td>4.830287</td>\n",
       "      <td>4.438642</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>0.232283</td>\n",
       "      <td>0.077023</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.076923</td>\n",
       "      <td>1.533742</td>\n",
       "      <td>4.447853</td>\n",
       "      <td>1.380368</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>1.533742</td>\n",
       "      <td>5.674847</td>\n",
       "      <td>1.993865</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>2.453988</td>\n",
       "      <td>...</td>\n",
       "      <td>5.521472</td>\n",
       "      <td>3.527607</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>9.355828</td>\n",
       "      <td>9.969325</td>\n",
       "      <td>5.368098</td>\n",
       "      <td>0.444785</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>56.166667</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>4.154303</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>0.593472</td>\n",
       "      <td>5.341246</td>\n",
       "      <td>2.670623</td>\n",
       "      <td>2.077151</td>\n",
       "      <td>4.747774</td>\n",
       "      <td>...</td>\n",
       "      <td>2.373887</td>\n",
       "      <td>5.044510</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>8.011869</td>\n",
       "      <td>7.715134</td>\n",
       "      <td>4.154303</td>\n",
       "      <td>0.554896</td>\n",
       "      <td>0.274336</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.183406</td>\n",
       "      <td>0.873362</td>\n",
       "      <td>0.436681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.240175</td>\n",
       "      <td>1.310044</td>\n",
       "      <td>3.493450</td>\n",
       "      <td>4.803493</td>\n",
       "      <td>...</td>\n",
       "      <td>3.056769</td>\n",
       "      <td>3.493450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.113537</td>\n",
       "      <td>4.366812</td>\n",
       "      <td>2.620087</td>\n",
       "      <td>0.620087</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.096070</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>18.095238</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>2.105263</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>5.789474</td>\n",
       "      <td>3.684211</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789474</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>18.947368</td>\n",
       "      <td>5.789474</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.362832</td>\n",
       "      <td>0.107895</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>16.611354</td>\n",
       "      <td>1.156677</td>\n",
       "      <td>2.970557</td>\n",
       "      <td>2.602524</td>\n",
       "      <td>1.445846</td>\n",
       "      <td>1.393270</td>\n",
       "      <td>2.628812</td>\n",
       "      <td>2.523659</td>\n",
       "      <td>1.919033</td>\n",
       "      <td>4.468980</td>\n",
       "      <td>...</td>\n",
       "      <td>3.548896</td>\n",
       "      <td>5.783386</td>\n",
       "      <td>0.578339</td>\n",
       "      <td>6.887487</td>\n",
       "      <td>10.778128</td>\n",
       "      <td>6.834911</td>\n",
       "      <td>0.289432</td>\n",
       "      <td>0.457865</td>\n",
       "      <td>0.128549</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>28.111111</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>4.743083</td>\n",
       "      <td>1.185771</td>\n",
       "      <td>1.185771</td>\n",
       "      <td>1.383399</td>\n",
       "      <td>4.743083</td>\n",
       "      <td>1.383399</td>\n",
       "      <td>1.581028</td>\n",
       "      <td>2.964427</td>\n",
       "      <td>...</td>\n",
       "      <td>5.138340</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.395257</td>\n",
       "      <td>5.731225</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>6.324111</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.261780</td>\n",
       "      <td>0.098814</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6080 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words_per_Sentence  Percentage_First_Person_Singular  \\\n",
       "0              28.866667                          0.000000   \n",
       "1              15.666667                          5.319149   \n",
       "2              24.709677                          0.000000   \n",
       "3              25.076923                          1.533742   \n",
       "4              25.000000                          0.000000   \n",
       "...                  ...                               ...   \n",
       "6075           56.166667                          0.296736   \n",
       "6076           22.900000                          0.000000   \n",
       "6077           18.095238                          1.842105   \n",
       "6078           16.611354                          1.156677   \n",
       "6079           28.111111                          0.988142   \n",
       "\n",
       "      Percentage_Third_Person  Percentage_Exclusive  Percentage_Negation  \\\n",
       "0                    2.078522              0.461894             0.000000   \n",
       "1                    5.851064              1.595745             1.063830   \n",
       "2                    1.958225              2.349869             1.174935   \n",
       "3                    4.447853              1.380368             0.613497   \n",
       "4                    2.000000              1.000000             0.000000   \n",
       "...                       ...                   ...                  ...   \n",
       "6075                 4.154303              1.186944             1.186944   \n",
       "6076                 2.183406              0.873362             0.436681   \n",
       "6077                 5.263158              2.105263             1.052632   \n",
       "6078                 2.970557              2.602524             1.445846   \n",
       "6079                 4.743083              1.185771             1.185771   \n",
       "\n",
       "      Percentage_Causation  Percentage_Sense  Percentage_PositiveEmo  \\\n",
       "0                 2.078522          1.154734                0.230947   \n",
       "1                 0.000000          0.000000                2.659574   \n",
       "2                 1.044386          6.527415                2.480418   \n",
       "3                 1.533742          5.674847                1.993865   \n",
       "4                 2.000000          2.000000                6.000000   \n",
       "...                    ...               ...                     ...   \n",
       "6075              0.593472          5.341246                2.670623   \n",
       "6076              0.000000          5.240175                1.310044   \n",
       "6077              1.315789          5.789474                3.684211   \n",
       "6078              1.393270          2.628812                2.523659   \n",
       "6079              1.383399          4.743083                1.383399   \n",
       "\n",
       "      Percentage_NegativeEmo  Percentage_AffectiveTerms  ...  \\\n",
       "0                   2.540416                   2.771363  ...   \n",
       "1                   0.000000                   2.659574  ...   \n",
       "2                   0.783290                   3.394256  ...   \n",
       "3                   0.460123                   2.453988  ...   \n",
       "4                   1.000000                   7.000000  ...   \n",
       "...                      ...                        ...  ...   \n",
       "6075                2.077151                   4.747774  ...   \n",
       "6076                3.493450                   4.803493  ...   \n",
       "6077                0.789474                   4.736842  ...   \n",
       "6078                1.919033                   4.468980  ...   \n",
       "6079                1.581028                   2.964427  ...   \n",
       "\n",
       "      Percentage_PastVerb  Percentage_PresentVerb  Percentage_FutureVerb  \\\n",
       "0                2.078522                2.078522               0.230947   \n",
       "1                1.595745                3.191489               0.000000   \n",
       "2                3.916449                4.569191               1.436031   \n",
       "3                5.521472                3.527607               0.460123   \n",
       "4                3.000000                2.000000               0.000000   \n",
       "...                   ...                     ...                    ...   \n",
       "6075             2.373887                5.044510               0.296736   \n",
       "6076             3.056769                3.493450               0.000000   \n",
       "6077             5.789474                4.736842               0.263158   \n",
       "6078             3.548896                5.783386               0.578339   \n",
       "6079             5.138340                4.347826               0.395257   \n",
       "\n",
       "      Percentage_Article  Percentage_Pronoun  Percentage_Conjunction  \\\n",
       "0              11.316397            6.004619                3.233256   \n",
       "1               5.851064           13.829787                2.659574   \n",
       "2               8.746736            4.830287                4.438642   \n",
       "3               9.355828            9.969325                5.368098   \n",
       "4              11.000000            3.000000                3.000000   \n",
       "...                  ...                 ...                     ...   \n",
       "6075            8.011869            7.715134                4.154303   \n",
       "6076            6.113537            4.366812                2.620087   \n",
       "6077            4.736842           18.947368                5.789474   \n",
       "6078            6.887487           10.778128                6.834911   \n",
       "6079            5.731225            8.695652                6.324111   \n",
       "\n",
       "      Lexical_Diversity  Emotiveness  Rate_of_Adjectives_Adverbs  \\\n",
       "0              0.496536     0.368421                    0.129330   \n",
       "1              0.595745     0.460000                    0.122340   \n",
       "2              0.437337     0.232283                    0.077023   \n",
       "3              0.444785     0.312500                    0.092025   \n",
       "4              0.690000     0.297297                    0.110000   \n",
       "...                 ...          ...                         ...   \n",
       "6075           0.554896     0.274336                    0.091988   \n",
       "6076           0.620087     0.271605                    0.096070   \n",
       "6077           0.484211     0.362832                    0.107895   \n",
       "6078           0.289432     0.457865                    0.128549   \n",
       "6079           0.521739     0.261780                    0.098814   \n",
       "\n",
       "      Flesch_Kincaid  \n",
       "0               11.8  \n",
       "1                7.7  \n",
       "2               11.0  \n",
       "3                9.7  \n",
       "4               11.5  \n",
       "...              ...  \n",
       "6075            12.0  \n",
       "6076            10.7  \n",
       "6077             6.8  \n",
       "6078             8.2  \n",
       "6079            10.0  \n",
       "\n",
       "[6080 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_linguistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words_per_Sentence</th>\n",
       "      <th>Percentage_First_Person_Singular</th>\n",
       "      <th>Percentage_Third_Person</th>\n",
       "      <th>Percentage_Exclusive</th>\n",
       "      <th>Percentage_Negation</th>\n",
       "      <th>Percentage_Causation</th>\n",
       "      <th>Percentage_Sense</th>\n",
       "      <th>Percentage_PositiveEmo</th>\n",
       "      <th>Percentage_NegativeEmo</th>\n",
       "      <th>Percentage_AffectiveTerms</th>\n",
       "      <th>...</th>\n",
       "      <th>Percentage_PastVerb</th>\n",
       "      <th>Percentage_PresentVerb</th>\n",
       "      <th>Percentage_FutureVerb</th>\n",
       "      <th>Percentage_Article</th>\n",
       "      <th>Percentage_Pronoun</th>\n",
       "      <th>Percentage_Conjunction</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Emotiveness</th>\n",
       "      <th>Rate_of_Adjectives_Adverbs</th>\n",
       "      <th>Flesch_Kincaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.393617</td>\n",
       "      <td>1.595745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.393617</td>\n",
       "      <td>7.446809</td>\n",
       "      <td>2.393617</td>\n",
       "      <td>1.861702</td>\n",
       "      <td>4.255319</td>\n",
       "      <td>...</td>\n",
       "      <td>6.648936</td>\n",
       "      <td>3.191489</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>11.170213</td>\n",
       "      <td>5.585106</td>\n",
       "      <td>5.585106</td>\n",
       "      <td>0.486702</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.103723</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.219178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.109589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>6.849315</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.466667</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>3.559871</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>1.779935</td>\n",
       "      <td>3.478964</td>\n",
       "      <td>2.831715</td>\n",
       "      <td>1.699029</td>\n",
       "      <td>4.530744</td>\n",
       "      <td>...</td>\n",
       "      <td>4.126214</td>\n",
       "      <td>2.993528</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>8.656958</td>\n",
       "      <td>6.877023</td>\n",
       "      <td>4.773463</td>\n",
       "      <td>0.411812</td>\n",
       "      <td>0.285360</td>\n",
       "      <td>0.093042</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>6.557377</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>...</td>\n",
       "      <td>6.557377</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>8.196721</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>26.708333</td>\n",
       "      <td>0.468019</td>\n",
       "      <td>4.680187</td>\n",
       "      <td>2.184087</td>\n",
       "      <td>0.936037</td>\n",
       "      <td>1.560062</td>\n",
       "      <td>1.872075</td>\n",
       "      <td>1.560062</td>\n",
       "      <td>2.808112</td>\n",
       "      <td>4.368175</td>\n",
       "      <td>...</td>\n",
       "      <td>3.432137</td>\n",
       "      <td>4.056162</td>\n",
       "      <td>1.092044</td>\n",
       "      <td>4.368175</td>\n",
       "      <td>11.076443</td>\n",
       "      <td>6.240250</td>\n",
       "      <td>0.436817</td>\n",
       "      <td>0.325472</td>\n",
       "      <td>0.107644</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>32.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.834862</td>\n",
       "      <td>0.305810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.587156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.504587</td>\n",
       "      <td>5.504587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.529052</td>\n",
       "      <td>4.892966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.785933</td>\n",
       "      <td>3.975535</td>\n",
       "      <td>4.892966</td>\n",
       "      <td>0.483180</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.137615</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>25.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.427083</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.822917</td>\n",
       "      <td>5.989583</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>6.510417</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>5.989583</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.297101</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>1.587302</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.984127</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.984127</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>17.125000</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>8.029197</td>\n",
       "      <td>5.109489</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>2.919708</td>\n",
       "      <td>5.109489</td>\n",
       "      <td>5.839416</td>\n",
       "      <td>2.919708</td>\n",
       "      <td>8.759124</td>\n",
       "      <td>...</td>\n",
       "      <td>2.919708</td>\n",
       "      <td>5.839416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.299270</td>\n",
       "      <td>13.868613</td>\n",
       "      <td>5.839416</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6081 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words_per_Sentence  Percentage_First_Person_Singular  \\\n",
       "0              25.066667                          0.000000   \n",
       "1              23.333333                          0.000000   \n",
       "2              24.333333                          0.000000   \n",
       "3              27.466667                          0.404531   \n",
       "4              40.666667                          0.000000   \n",
       "...                  ...                               ...   \n",
       "6076           26.708333                          0.468019   \n",
       "6077           32.700000                          0.000000   \n",
       "6078           25.600000                          0.000000   \n",
       "6079           63.000000                          0.000000   \n",
       "6080           17.125000                          0.729927   \n",
       "\n",
       "      Percentage_Third_Person  Percentage_Exclusive  Percentage_Negation  \\\n",
       "0                    2.393617              1.595745             0.000000   \n",
       "1                    2.857143              2.857143             2.857143   \n",
       "2                    1.369863              1.369863             1.369863   \n",
       "3                    3.559871              0.566343             0.485437   \n",
       "4                    3.278689              0.819672             0.000000   \n",
       "...                       ...                   ...                  ...   \n",
       "6076                 4.680187              2.184087             0.936037   \n",
       "6077                 1.834862              0.305810             0.000000   \n",
       "6078                 4.427083              0.781250             0.520833   \n",
       "6079                 5.555556              2.777778             0.000000   \n",
       "6080                 8.029197              5.109489             0.729927   \n",
       "\n",
       "      Percentage_Causation  Percentage_Sense  Percentage_PositiveEmo  \\\n",
       "0                 2.393617          7.446809                2.393617   \n",
       "1                 2.142857          2.857143                2.142857   \n",
       "2                 0.000000          8.219178                0.000000   \n",
       "3                 1.779935          3.478964                2.831715   \n",
       "4                 3.278689          6.557377                2.459016   \n",
       "...                    ...               ...                     ...   \n",
       "6076              1.560062          1.872075                1.560062   \n",
       "6077              0.000000          4.587156                0.000000   \n",
       "6078              3.125000          2.083333                4.687500   \n",
       "6079              0.793651          2.380952                1.190476   \n",
       "6080              2.919708          5.109489                5.839416   \n",
       "\n",
       "      Percentage_NegativeEmo  Percentage_AffectiveTerms  ...  \\\n",
       "0                   1.861702                   4.255319  ...   \n",
       "1                   0.000000                   2.142857  ...   \n",
       "2                   0.000000                   0.000000  ...   \n",
       "3                   1.699029                   4.530744  ...   \n",
       "4                   2.459016                   4.918033  ...   \n",
       "...                      ...                        ...  ...   \n",
       "6076                2.808112                   4.368175  ...   \n",
       "6077                5.504587                   5.504587  ...   \n",
       "6078                1.562500                   6.250000  ...   \n",
       "6079                1.587302                   2.777778  ...   \n",
       "6080                2.919708                   8.759124  ...   \n",
       "\n",
       "      Percentage_PastVerb  Percentage_PresentVerb  Percentage_FutureVerb  \\\n",
       "0                6.648936                3.191489               0.797872   \n",
       "1                7.857143                1.428571               2.142857   \n",
       "2                4.109589                0.000000               1.369863   \n",
       "3                4.126214                2.993528               0.485437   \n",
       "4                6.557377                3.278689               0.819672   \n",
       "...                   ...                     ...                    ...   \n",
       "6076             3.432137                4.056162               1.092044   \n",
       "6077             1.529052                4.892966               0.000000   \n",
       "6078             1.822917                5.989583               0.781250   \n",
       "6079             2.777778                1.984127               0.793651   \n",
       "6080             2.919708                5.839416               0.000000   \n",
       "\n",
       "      Percentage_Article  Percentage_Pronoun  Percentage_Conjunction  \\\n",
       "0              11.170213            5.585106                5.585106   \n",
       "1               5.000000            9.285714                1.428571   \n",
       "2               6.849315            1.369863                1.369863   \n",
       "3               8.656958            6.877023                4.773463   \n",
       "4               8.196721            4.918033                2.459016   \n",
       "...                  ...                 ...                     ...   \n",
       "6076            4.368175           11.076443                6.240250   \n",
       "6077            9.785933            3.975535                4.892966   \n",
       "6078            6.510417            5.468750                5.989583   \n",
       "6079            8.333333            8.333333                1.984127   \n",
       "6080            7.299270           13.868613                5.839416   \n",
       "\n",
       "      Lexical_Diversity  Emotiveness  Rate_of_Adjectives_Adverbs  \\\n",
       "0              0.486702     0.345133                    0.103723   \n",
       "1              0.742857     0.137255                    0.050000   \n",
       "2              0.698630     0.181818                    0.054795   \n",
       "3              0.411812     0.285360                    0.093042   \n",
       "4              0.672131     0.472222                    0.139344   \n",
       "...                 ...          ...                         ...   \n",
       "6076           0.436817     0.325472                    0.107644   \n",
       "6077           0.483180     0.405405                    0.137615   \n",
       "6078           0.476562     0.297101                    0.106771   \n",
       "6079           0.575397     0.270000                    0.107143   \n",
       "6080           0.671533     0.326531                    0.116788   \n",
       "\n",
       "      Flesch_Kincaid  \n",
       "0                9.9  \n",
       "1               12.0  \n",
       "2                7.7  \n",
       "3               11.6  \n",
       "4               12.4  \n",
       "...              ...  \n",
       "6076            10.1  \n",
       "6077            10.4  \n",
       "6078            11.2  \n",
       "6079            26.6  \n",
       "6080             7.3  \n",
       "\n",
       "[6081 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_linguistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization and lowercase\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]  # Remove stopwords and lemmatize\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        beirut ( reuters ) - iran military chief met s...\n",
      "1        hanoi ( reuters ) - top u.s. envoy began two-d...\n",
      "2        ( reuters ) - four u.s. senator asked senate j...\n",
      "3        first read morning briefing meet press nbc pol...\n",
      "4        cairo ( reuters ) - six month egypt election ,...\n",
      "                               ...                        \n",
      "54714    lack oversight prof donald trump totally unfit...\n",
      "54715    tucker carlson responded espn anchor calling p...\n",
      "54716    getting something nothing rage president profe...\n",
      "54717    black emanuelle fixed 1976. attila speaking eu...\n",
      "54718    chaos broke legal american illegal alien clash...\n",
      "Name: text, Length: 54719, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        beirut (reuters) - iran s military chief met w...\n",
      "1        hanoi (reuters) - a top u.s. envoy began a two...\n",
      "2        (reuters) - four u.s. senators have asked the ...\n",
      "3        first read is a morning briefing from meet the...\n",
      "4        cairo (reuters) - six months before egypt s el...\n",
      "                               ...                        \n",
      "54714    this lack of oversight proves that donald trum...\n",
      "54715    tucker carlson responded to an espn anchor cal...\n",
      "54716    because getting something for nothing is all t...\n",
      "54717    black emanuelle fixed all that in 1976. attila...\n",
      "54718    chaos broke out after legal americans and ille...\n",
      "Name: text, Length: 54719, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer without specifying max_features\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169079\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique tokens\n",
    "num_unique_tokens = len(tfidf_vectorizer.get_feature_names_out())\n",
    "print(num_unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize TF-IDF vectorizer with the determined max_features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=num_unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498\n"
     ]
    }
   ],
   "source": [
    "#Fit and transform the text data again with the updated max_features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_preprocessed)\n",
    "\n",
    "# Convert the TF-IDF matrix to a CSR (Compressed Sparse Row) matrix for efficient row-wise operations\n",
    "csr_tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# Find the row index with the maximum number of filled values\n",
    "max_features_row_index = csr_tfidf_matrix.getnnz(axis=1).argmax()\n",
    "\n",
    "# Get the number of features in the document with the most filled values\n",
    "max_features = csr_tfidf_matrix[max_features_row_index].count_nonzero()\n",
    "\n",
    "print(max_features)\n",
    "\n",
    "svd = TruncatedSVD(n_components=int(max_features*0.3))\n",
    "tfidf_matrix = svd.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_tfidf_matrix = tfidf_matrix[:len(train_data)]\n",
    "dense_tfidf_with_linguistic = hstack([dense_tfidf_matrix, csr_matrix(linguistic_features)])\n",
    "\n",
    "dense_val_tfidf_matrix = tfidf_matrix[len(train_data):len(train_data) + len(val_data)]\n",
    "dense_val_tfidf_with_linguistic = hstack([dense_val_tfidf_matrix, csr_matrix(val_linguistic_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the CNN + Bi-LSTM model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(dense_tfidf_with_linguistic.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define the Bi-LSTM model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(tfidf_matrix.shape[1],1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1520/1520 [==============================] - 544s 351ms/step - loss: 0.4435 - accuracy: 0.7915 - val_loss: 0.3030 - val_accuracy: 0.8694 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1520/1520 [==============================] - 539s 354ms/step - loss: 0.3048 - accuracy: 0.8723 - val_loss: 0.2719 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1520/1520 [==============================] - 537s 353ms/step - loss: 0.2808 - accuracy: 0.8841 - val_loss: 0.2575 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1520/1520 [==============================] - 533s 350ms/step - loss: 0.2683 - accuracy: 0.8896 - val_loss: 0.2855 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1520/1520 [==============================] - 494s 325ms/step - loss: 0.2594 - accuracy: 0.8951 - val_loss: 0.2491 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1520/1520 [==============================] - 526s 346ms/step - loss: 0.2496 - accuracy: 0.8980 - val_loss: 0.2489 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1520/1520 [==============================] - 817s 538ms/step - loss: 0.2423 - accuracy: 0.9034 - val_loss: 0.2371 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1520/1520 [==============================] - 880s 579ms/step - loss: 0.2337 - accuracy: 0.9065 - val_loss: 0.2334 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1520/1520 [==============================] - 934s 615ms/step - loss: 0.2284 - accuracy: 0.9079 - val_loss: 0.2287 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1520/1520 [==============================] - 906s 596ms/step - loss: 0.2212 - accuracy: 0.9112 - val_loss: 0.2217 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1520/1520 [==============================] - 847s 558ms/step - loss: 0.2156 - accuracy: 0.9147 - val_loss: 0.2183 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1520/1520 [==============================] - 824s 542ms/step - loss: 0.2098 - accuracy: 0.9165 - val_loss: 0.2208 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1520/1520 [==============================] - 827s 544ms/step - loss: 0.2064 - accuracy: 0.9189 - val_loss: 0.2212 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1520/1520 [==============================] - 823s 542ms/step - loss: 0.2011 - accuracy: 0.9200 - val_loss: 0.2251 - val_accuracy: 0.9099 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1520/1520 [==============================] - 851s 560ms/step - loss: 0.1966 - accuracy: 0.9232 - val_loss: 0.2368 - val_accuracy: 0.9054 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1520/1520 [==============================] - 741s 487ms/step - loss: 0.1925 - accuracy: 0.9239 - val_loss: 0.2109 - val_accuracy: 0.9123 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1520/1520 [==============================] - 674s 444ms/step - loss: 0.1871 - accuracy: 0.9248 - val_loss: 0.2134 - val_accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1520/1520 [==============================] - 676s 445ms/step - loss: 0.1821 - accuracy: 0.9273 - val_loss: 0.2183 - val_accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1520/1520 [==============================] - 680s 448ms/step - loss: 0.1777 - accuracy: 0.9294 - val_loss: 0.2199 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1520/1520 [==============================] - 680s 447ms/step - loss: 0.1754 - accuracy: 0.9312 - val_loss: 0.2204 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1520/1520 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9329\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1520/1520 [==============================] - 682s 449ms/step - loss: 0.1696 - accuracy: 0.9329 - val_loss: 0.2252 - val_accuracy: 0.9104 - lr: 0.0010\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f53c5b8a00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming train_data['label'] and val_data['label'] are Pandas Series, convert them to arrays\n",
    "train_labels = train_data['label'].values\n",
    "val_labels = val_data['label'].values\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "\n",
    "# Reshape the input data\n",
    "dense_tfidf_with_linguistic = dense_tfidf_with_linguistic.toarray()  # Convert to dense array\n",
    "dense_val_tfidf_with_linguistic = dense_val_tfidf_with_linguistic.toarray()  # Convert to dense array\n",
    "\n",
    "# Fit the model using NumPy arrays with callbacks\n",
    "model.fit(dense_tfidf_with_linguistic, train_labels, \n",
    "          epochs=100, batch_size=32, \n",
    "          validation_data=(dense_val_tfidf_with_linguistic, val_labels),\n",
    "          callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 25s 112ms/step - loss: 0.2307 - accuracy: 0.9117\n",
      "Test accuracy: 0.9116921424865723\n"
     ]
    }
   ],
   "source": [
    "text_test_preprocessed = text_test.apply(preprocess_text)\n",
    "test_tfidf_matrix = tfidf_vectorizer.transform(text_test_preprocessed)\n",
    "dense_test_tfidf_matrix = svd.transform(test_tfidf_matrix)\n",
    "dense_test_tfidf_with_linguistic = hstack([dense_test_tfidf_matrix, csr_matrix(test_linguistic_features)])\n",
    "test_labels = test_data['label'].values\n",
    "\n",
    "dense_test_tfidf_with_linguistic = dense_test_tfidf_with_linguistic.toarray()  # Convert to dense array\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "test_loss, test_accuracy = model.evaluate(dense_test_tfidf_with_linguistic, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bi_lstm_tfidf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5543.999918460846"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy * lengthTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
