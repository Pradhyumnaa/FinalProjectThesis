{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "val_data = pd.read_csv('val.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "lengthTestData = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text data for preprocessing\n",
    "text = pd.concat([train_data['text'], val_data['text']], ignore_index=True)\n",
    "text_test = test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_features = pd.concat([train_data.iloc[:,-9:], val_data.iloc[:,-9:]], ignore_index=True)\n",
    "test_linguistic_features = test_data.iloc[:,-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words_per_Sentence</th>\n",
       "      <th>Percentage_Questions</th>\n",
       "      <th>Percentage_First_Person_Singular</th>\n",
       "      <th>Percentage_Second_Person</th>\n",
       "      <th>Percentage_Third_Person</th>\n",
       "      <th>Percentage_Negation</th>\n",
       "      <th>Percentage_Exclusive</th>\n",
       "      <th>Percentage_Causation</th>\n",
       "      <th>Percentage_Sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.930502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>5.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.735562</td>\n",
       "      <td>0.607903</td>\n",
       "      <td>1.519757</td>\n",
       "      <td>1.519757</td>\n",
       "      <td>4.863222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.191781</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>1.095890</td>\n",
       "      <td>6.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.254545</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>0.085543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.790419</td>\n",
       "      <td>1.197605</td>\n",
       "      <td>1.710864</td>\n",
       "      <td>2.138580</td>\n",
       "      <td>3.079555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>6.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54714</th>\n",
       "      <td>56.166667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.154303</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>0.593472</td>\n",
       "      <td>5.341246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54715</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.183406</td>\n",
       "      <td>0.436681</td>\n",
       "      <td>0.873362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.240175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54716</th>\n",
       "      <td>18.095238</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>3.684211</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>2.105263</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>5.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54717</th>\n",
       "      <td>16.611354</td>\n",
       "      <td>10.043668</td>\n",
       "      <td>1.156677</td>\n",
       "      <td>2.576236</td>\n",
       "      <td>2.970557</td>\n",
       "      <td>1.445846</td>\n",
       "      <td>2.602524</td>\n",
       "      <td>1.393270</td>\n",
       "      <td>2.628812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54718</th>\n",
       "      <td>28.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.988142</td>\n",
       "      <td>0.592885</td>\n",
       "      <td>4.743083</td>\n",
       "      <td>1.185771</td>\n",
       "      <td>1.185771</td>\n",
       "      <td>1.383399</td>\n",
       "      <td>4.743083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54719 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words_per_Sentence  Percentage_Questions  \\\n",
       "0               28.777778              0.000000   \n",
       "1               32.900000              0.000000   \n",
       "2               30.416667              0.000000   \n",
       "3               21.254545              3.636364   \n",
       "4               24.444444              0.000000   \n",
       "...                   ...                   ...   \n",
       "54714           56.166667             16.666667   \n",
       "54715           22.900000              0.000000   \n",
       "54716           18.095238             14.285714   \n",
       "54717           16.611354             10.043668   \n",
       "54718           28.111111             11.111111   \n",
       "\n",
       "       Percentage_First_Person_Singular  Percentage_Second_Person  \\\n",
       "0                              0.000000                  0.000000   \n",
       "1                              0.000000                  0.000000   \n",
       "2                              0.000000                  0.000000   \n",
       "3                              0.085543                  0.000000   \n",
       "4                              0.000000                  0.090909   \n",
       "...                                 ...                       ...   \n",
       "54714                          0.296736                  0.000000   \n",
       "54715                          0.000000                  0.000000   \n",
       "54716                          1.842105                  3.684211   \n",
       "54717                          1.156677                  2.576236   \n",
       "54718                          0.988142                  0.592885   \n",
       "\n",
       "       Percentage_Third_Person  Percentage_Negation  Percentage_Exclusive  \\\n",
       "0                     1.930502             0.000000              0.000000   \n",
       "1                     2.735562             0.607903              1.519757   \n",
       "2                     2.191781             0.547945              0.821918   \n",
       "3                     4.790419             1.197605              1.710864   \n",
       "4                     3.181818             0.545455              1.636364   \n",
       "...                        ...                  ...                   ...   \n",
       "54714                 4.154303             1.186944              1.186944   \n",
       "54715                 2.183406             0.436681              0.873362   \n",
       "54716                 5.263158             1.052632              2.105263   \n",
       "54717                 2.970557             1.445846              2.602524   \n",
       "54718                 4.743083             1.185771              1.185771   \n",
       "\n",
       "       Percentage_Causation  Percentage_Sense  \n",
       "0                  2.702703          5.405405  \n",
       "1                  1.519757          4.863222  \n",
       "2                  1.095890          6.027397  \n",
       "3                  2.138580          3.079555  \n",
       "4                  2.181818          6.181818  \n",
       "...                     ...               ...  \n",
       "54714              0.593472          5.341246  \n",
       "54715              0.000000          5.240175  \n",
       "54716              1.315789          5.789474  \n",
       "54717              1.393270          2.628812  \n",
       "54718              1.383399          4.743083  \n",
       "\n",
       "[54719 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linguistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words_per_Sentence</th>\n",
       "      <th>Percentage_Questions</th>\n",
       "      <th>Percentage_First_Person_Singular</th>\n",
       "      <th>Percentage_Second_Person</th>\n",
       "      <th>Percentage_Third_Person</th>\n",
       "      <th>Percentage_Negation</th>\n",
       "      <th>Percentage_Exclusive</th>\n",
       "      <th>Percentage_Causation</th>\n",
       "      <th>Percentage_Sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>2.393617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.595745</td>\n",
       "      <td>2.393617</td>\n",
       "      <td>7.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.219178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>0.242718</td>\n",
       "      <td>3.559871</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>1.779935</td>\n",
       "      <td>3.478964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>6.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>26.708333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.468019</td>\n",
       "      <td>0.624025</td>\n",
       "      <td>4.680187</td>\n",
       "      <td>0.936037</td>\n",
       "      <td>2.184087</td>\n",
       "      <td>1.560062</td>\n",
       "      <td>1.872075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>32.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.834862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.587156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>25.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.427083</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>2.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>17.125000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.029197</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>5.109489</td>\n",
       "      <td>2.919708</td>\n",
       "      <td>5.109489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6081 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words_per_Sentence  Percentage_Questions  \\\n",
       "0              25.066667              0.000000   \n",
       "1              23.333333              0.000000   \n",
       "2              24.333333              0.000000   \n",
       "3              27.466667              0.000000   \n",
       "4              40.666667              0.000000   \n",
       "...                  ...                   ...   \n",
       "6076           26.708333              8.333333   \n",
       "6077           32.700000              0.000000   \n",
       "6078           25.600000              0.000000   \n",
       "6079           63.000000              0.000000   \n",
       "6080           17.125000             25.000000   \n",
       "\n",
       "      Percentage_First_Person_Singular  Percentage_Second_Person  \\\n",
       "0                             0.000000                  0.265957   \n",
       "1                             0.000000                  0.000000   \n",
       "2                             0.000000                  0.000000   \n",
       "3                             0.404531                  0.242718   \n",
       "4                             0.000000                  0.000000   \n",
       "...                                ...                       ...   \n",
       "6076                          0.468019                  0.624025   \n",
       "6077                          0.000000                  0.000000   \n",
       "6078                          0.000000                  0.000000   \n",
       "6079                          0.000000                  0.000000   \n",
       "6080                          0.729927                  0.000000   \n",
       "\n",
       "      Percentage_Third_Person  Percentage_Negation  Percentage_Exclusive  \\\n",
       "0                    2.393617             0.000000              1.595745   \n",
       "1                    2.857143             2.857143              2.857143   \n",
       "2                    1.369863             1.369863              1.369863   \n",
       "3                    3.559871             0.485437              0.566343   \n",
       "4                    3.278689             0.000000              0.819672   \n",
       "...                       ...                  ...                   ...   \n",
       "6076                 4.680187             0.936037              2.184087   \n",
       "6077                 1.834862             0.000000              0.305810   \n",
       "6078                 4.427083             0.520833              0.781250   \n",
       "6079                 5.555556             0.000000              2.777778   \n",
       "6080                 8.029197             0.729927              5.109489   \n",
       "\n",
       "      Percentage_Causation  Percentage_Sense  \n",
       "0                 2.393617          7.446809  \n",
       "1                 2.142857          2.857143  \n",
       "2                 0.000000          8.219178  \n",
       "3                 1.779935          3.478964  \n",
       "4                 3.278689          6.557377  \n",
       "...                    ...               ...  \n",
       "6076              1.560062          1.872075  \n",
       "6077              0.000000          4.587156  \n",
       "6078              3.125000          2.083333  \n",
       "6079              0.793651          2.380952  \n",
       "6080              2.919708          5.109489  \n",
       "\n",
       "[6081 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_linguistic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization and lowercase\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]  # Remove stopwords and lemmatize\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        beirut ( reuters ) - iran military chief met s...\n",
      "1        hanoi ( reuters ) - top u.s. envoy began two-d...\n",
      "2        ( reuters ) - four u.s. senator asked senate j...\n",
      "3        first read morning briefing meet press nbc pol...\n",
      "4        cairo ( reuters ) - six month egypt election ,...\n",
      "                               ...                        \n",
      "54714    lack oversight prof donald trump totally unfit...\n",
      "54715    tucker carlson responded espn anchor calling p...\n",
      "54716    getting something nothing rage president profe...\n",
      "54717    black emanuelle fixed 1976. attila speaking eu...\n",
      "54718    chaos broke legal american illegal alien clash...\n",
      "Name: text, Length: 54719, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        beirut (reuters) - iran s military chief met w...\n",
      "1        hanoi (reuters) - a top u.s. envoy began a two...\n",
      "2        (reuters) - four u.s. senators have asked the ...\n",
      "3        first read is a morning briefing from meet the...\n",
      "4        cairo (reuters) - six months before egypt s el...\n",
      "                               ...                        \n",
      "54714    this lack of oversight proves that donald trum...\n",
      "54715    tucker carlson responded to an espn anchor cal...\n",
      "54716    because getting something for nothing is all t...\n",
      "54717    black emanuelle fixed all that in 1976. attila...\n",
      "54718    chaos broke out after legal americans and ille...\n",
      "Name: text, Length: 54719, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer without specifying max_features\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169079\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique tokens\n",
    "num_unique_tokens = len(tfidf_vectorizer.get_feature_names_out())\n",
    "print(num_unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize TF-IDF vectorizer with the determined max_features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=num_unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform the text data again with the updated max_features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_preprocessed)\n",
    "\n",
    "# Convert the TF-IDF matrix to a CSR (Compressed Sparse Row) matrix for efficient row-wise operations\n",
    "csr_tfidf_matrix = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# Find the row index with the maximum number of filled values\n",
    "max_features_row_index = csr_tfidf_matrix.getnnz(axis=1).argmax()\n",
    "\n",
    "# Get the number of features in the document with the most filled values\n",
    "max_features = csr_tfidf_matrix[max_features_row_index].count_nonzero()\n",
    "\n",
    "svd = TruncatedSVD(n_components=int(max_features*0.3))\n",
    "tfidf_matrix = svd.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_tfidf_matrix = tfidf_matrix[:len(train_data)]\n",
    "#dense_val_tfidf_matrix = tfidf_matrix[len(train_data):len(train_data) + len(val_data)]\n",
    "\n",
    "# Merging the Validation and Training Data into one for a larger training dataset.\n",
    "#dense_tfidf_matrix = tfidf_matrix[:len(train_data) + len(val_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate linguistic features and TF-IDF matrix horizontally\n",
    "dense_tfidf_with_linguistic = hstack([tfidf_matrix, csr_matrix(linguistic_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert them into Arrays\n",
    "train_labels = train_data['label'].values\n",
    "val_labels = val_data['label'].values\n",
    "\n",
    "dense_labels = np.concatenate((train_data['label'].values, val_data['label'].values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the MLP model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(600, 10), max_iter=300, activation='relu', solver='adam', learning_rate='adaptive', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37072631\n",
      "Iteration 2, loss = 0.14625432\n",
      "Iteration 3, loss = 0.12174586\n",
      "Iteration 4, loss = 0.11074755\n",
      "Iteration 5, loss = 0.11026996\n",
      "Iteration 6, loss = 0.10514726\n",
      "Iteration 7, loss = 0.10468376\n",
      "Iteration 8, loss = 0.09158401\n",
      "Iteration 9, loss = 0.08801302\n",
      "Iteration 10, loss = 0.08264857\n",
      "Iteration 11, loss = 0.07460030\n",
      "Iteration 12, loss = 0.07454546\n",
      "Iteration 13, loss = 0.06756463\n",
      "Iteration 14, loss = 0.05969429\n",
      "Iteration 15, loss = 0.05578566\n",
      "Iteration 16, loss = 0.05426848\n",
      "Iteration 17, loss = 0.04497476\n",
      "Iteration 18, loss = 0.04038199\n",
      "Iteration 19, loss = 0.03768006\n",
      "Iteration 20, loss = 0.03174275\n",
      "Iteration 21, loss = 0.03395739\n",
      "Iteration 22, loss = 0.02494772\n",
      "Iteration 23, loss = 0.01996430\n",
      "Iteration 24, loss = 0.01838851\n",
      "Iteration 25, loss = 0.01595186\n",
      "Iteration 26, loss = 0.01255287\n",
      "Iteration 27, loss = 0.01219638\n",
      "Iteration 28, loss = 0.01505597\n",
      "Iteration 29, loss = 0.01269621\n",
      "Iteration 30, loss = 0.01363711\n",
      "Iteration 31, loss = 0.01835012\n",
      "Iteration 32, loss = 0.00706033\n",
      "Iteration 33, loss = 0.00511161\n",
      "Iteration 34, loss = 0.00466806\n",
      "Iteration 35, loss = 0.00475205\n",
      "Iteration 36, loss = 0.00486559\n",
      "Iteration 37, loss = 0.00534911\n",
      "Iteration 38, loss = 0.03826711\n",
      "Iteration 39, loss = 0.01043868\n",
      "Iteration 40, loss = 0.00558787\n",
      "Iteration 41, loss = 0.00421930\n",
      "Iteration 42, loss = 0.00362873\n",
      "Iteration 43, loss = 0.00374661\n",
      "Iteration 44, loss = 0.00349901\n",
      "Iteration 45, loss = 0.00333058\n",
      "Iteration 46, loss = 0.00353831\n",
      "Iteration 47, loss = 0.00373060\n",
      "Iteration 48, loss = 0.03029171\n",
      "Iteration 49, loss = 0.01037960\n",
      "Iteration 50, loss = 0.00485036\n",
      "Iteration 51, loss = 0.01766902\n",
      "Iteration 52, loss = 0.01318464\n",
      "Iteration 53, loss = 0.00414050\n",
      "Iteration 54, loss = 0.00354019\n",
      "Iteration 55, loss = 0.00338320\n",
      "Iteration 56, loss = 0.00357482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.36470618\n",
      "Iteration 2, loss = 0.15134924\n",
      "Iteration 3, loss = 0.12089057\n",
      "Iteration 4, loss = 0.10888135\n",
      "Iteration 5, loss = 0.10412458\n",
      "Iteration 6, loss = 0.09882324\n",
      "Iteration 7, loss = 0.09422141\n",
      "Iteration 8, loss = 0.09307371\n",
      "Iteration 9, loss = 0.08490529\n",
      "Iteration 10, loss = 0.08005352\n",
      "Iteration 11, loss = 0.07428588\n",
      "Iteration 12, loss = 0.06666866\n",
      "Iteration 13, loss = 0.06409637\n",
      "Iteration 14, loss = 0.05882420\n",
      "Iteration 15, loss = 0.05363436\n",
      "Iteration 16, loss = 0.04903796\n",
      "Iteration 17, loss = 0.04708385\n",
      "Iteration 18, loss = 0.04267883\n",
      "Iteration 19, loss = 0.03527090\n",
      "Iteration 20, loss = 0.03034697\n",
      "Iteration 21, loss = 0.02837105\n",
      "Iteration 22, loss = 0.02326357\n",
      "Iteration 23, loss = 0.01951373\n",
      "Iteration 24, loss = 0.01891188\n",
      "Iteration 25, loss = 0.02363175\n",
      "Iteration 26, loss = 0.01891906\n",
      "Iteration 27, loss = 0.01215534\n",
      "Iteration 28, loss = 0.01120855\n",
      "Iteration 29, loss = 0.01422683\n",
      "Iteration 30, loss = 0.01064542\n",
      "Iteration 31, loss = 0.01006742\n",
      "Iteration 32, loss = 0.01057928\n",
      "Iteration 33, loss = 0.01216771\n",
      "Iteration 34, loss = 0.01272423\n",
      "Iteration 35, loss = 0.00598260\n",
      "Iteration 36, loss = 0.00470741\n",
      "Iteration 37, loss = 0.00404708\n",
      "Iteration 38, loss = 0.00380332\n",
      "Iteration 39, loss = 0.00357143\n",
      "Iteration 40, loss = 0.01151304\n",
      "Iteration 41, loss = 0.04850052\n",
      "Iteration 42, loss = 0.01097965\n",
      "Iteration 43, loss = 0.00607006\n",
      "Iteration 44, loss = 0.00482658\n",
      "Iteration 45, loss = 0.00430297\n",
      "Iteration 46, loss = 0.00382553\n",
      "Iteration 47, loss = 0.00372757\n",
      "Iteration 48, loss = 0.00429637\n",
      "Iteration 49, loss = 0.03222656\n",
      "Iteration 50, loss = 0.01393086\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.34617686\n",
      "Iteration 2, loss = 0.14492922\n",
      "Iteration 3, loss = 0.12028560\n",
      "Iteration 4, loss = 0.11046712\n",
      "Iteration 5, loss = 0.10798220\n",
      "Iteration 6, loss = 0.10374308\n",
      "Iteration 7, loss = 0.09540198\n",
      "Iteration 8, loss = 0.08769940\n",
      "Iteration 9, loss = 0.08787391\n",
      "Iteration 10, loss = 0.08592612\n",
      "Iteration 11, loss = 0.06988975\n",
      "Iteration 12, loss = 0.07223187\n",
      "Iteration 13, loss = 0.06667461\n",
      "Iteration 14, loss = 0.05532640\n",
      "Iteration 15, loss = 0.05183433\n",
      "Iteration 16, loss = 0.04634008\n",
      "Iteration 17, loss = 0.04105365\n",
      "Iteration 18, loss = 0.03606838\n",
      "Iteration 19, loss = 0.03414929\n",
      "Iteration 20, loss = 0.02914404\n",
      "Iteration 21, loss = 0.02929798\n",
      "Iteration 22, loss = 0.02098373\n",
      "Iteration 23, loss = 0.01737668\n",
      "Iteration 24, loss = 0.02070140\n",
      "Iteration 25, loss = 0.01382674\n",
      "Iteration 26, loss = 0.01065733\n",
      "Iteration 27, loss = 0.02121876\n",
      "Iteration 28, loss = 0.01278924\n",
      "Iteration 29, loss = 0.00797059\n",
      "Iteration 30, loss = 0.00743797\n",
      "Iteration 31, loss = 0.01536992\n",
      "Iteration 32, loss = 0.02868630\n",
      "Iteration 33, loss = 0.01326479\n",
      "Iteration 34, loss = 0.00493921\n",
      "Iteration 35, loss = 0.00419808\n",
      "Iteration 36, loss = 0.00371468\n",
      "Iteration 37, loss = 0.00348993\n",
      "Iteration 38, loss = 0.00326724\n",
      "Iteration 39, loss = 0.00315016\n",
      "Iteration 40, loss = 0.02194282\n",
      "Iteration 41, loss = 0.01480666\n",
      "Iteration 42, loss = 0.00708076\n",
      "Iteration 43, loss = 0.00379580\n",
      "Iteration 44, loss = 0.00563765\n",
      "Iteration 45, loss = 0.00382738\n",
      "Iteration 46, loss = 0.00425827\n",
      "Iteration 47, loss = 0.00316631\n",
      "Iteration 48, loss = 0.02740249\n",
      "Iteration 49, loss = 0.01017110\n",
      "Iteration 50, loss = 0.00504380\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.37274959\n",
      "Iteration 2, loss = 0.14488267\n",
      "Iteration 3, loss = 0.12127447\n",
      "Iteration 4, loss = 0.11174235\n",
      "Iteration 5, loss = 0.10358024\n",
      "Iteration 6, loss = 0.10038388\n",
      "Iteration 7, loss = 0.09377320\n",
      "Iteration 8, loss = 0.09158800\n",
      "Iteration 9, loss = 0.08211278\n",
      "Iteration 10, loss = 0.08176683\n",
      "Iteration 11, loss = 0.07325050\n",
      "Iteration 12, loss = 0.06631980\n",
      "Iteration 13, loss = 0.06018629\n",
      "Iteration 14, loss = 0.05771964\n",
      "Iteration 15, loss = 0.05115383\n",
      "Iteration 16, loss = 0.04297002\n",
      "Iteration 17, loss = 0.04377631\n",
      "Iteration 18, loss = 0.03904384\n",
      "Iteration 19, loss = 0.03205292\n",
      "Iteration 20, loss = 0.02549680\n",
      "Iteration 21, loss = 0.02391493\n",
      "Iteration 22, loss = 0.02119963\n",
      "Iteration 23, loss = 0.02178550\n",
      "Iteration 24, loss = 0.02057099\n",
      "Iteration 25, loss = 0.01623573\n",
      "Iteration 26, loss = 0.01036740\n",
      "Iteration 27, loss = 0.00947989\n",
      "Iteration 28, loss = 0.00777870\n",
      "Iteration 29, loss = 0.03018890\n",
      "Iteration 30, loss = 0.01053339\n",
      "Iteration 31, loss = 0.00618747\n",
      "Iteration 32, loss = 0.01030853\n",
      "Iteration 33, loss = 0.00735498\n",
      "Iteration 34, loss = 0.00455440\n",
      "Iteration 35, loss = 0.00386696\n",
      "Iteration 36, loss = 0.00384708\n",
      "Iteration 37, loss = 0.00351866\n",
      "Iteration 38, loss = 0.00435755\n",
      "Iteration 39, loss = 0.03977174\n",
      "Iteration 40, loss = 0.01260126\n",
      "Iteration 41, loss = 0.00562067\n",
      "Iteration 42, loss = 0.00502171\n",
      "Iteration 43, loss = 0.00368740\n",
      "Iteration 44, loss = 0.00329478\n",
      "Iteration 45, loss = 0.00320634\n",
      "Iteration 46, loss = 0.00323969\n",
      "Iteration 47, loss = 0.00331084\n",
      "Iteration 48, loss = 0.02664296\n",
      "Iteration 49, loss = 0.01545063\n",
      "Iteration 50, loss = 0.00652563\n",
      "Iteration 51, loss = 0.00747099\n",
      "Iteration 52, loss = 0.00483000\n",
      "Iteration 53, loss = 0.00320505\n",
      "Iteration 54, loss = 0.00317191\n",
      "Iteration 55, loss = 0.00302284\n",
      "Iteration 56, loss = 0.00303570\n",
      "Iteration 57, loss = 0.00301080\n",
      "Iteration 58, loss = 0.00307020\n",
      "Iteration 59, loss = 0.00316950\n",
      "Iteration 60, loss = 0.00292334\n",
      "Iteration 61, loss = 0.04979339\n",
      "Iteration 62, loss = 0.00574241\n",
      "Iteration 63, loss = 0.00872999\n",
      "Iteration 64, loss = 0.00372492\n",
      "Iteration 65, loss = 0.00360678\n",
      "Iteration 66, loss = 0.00491689\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.35728502\n",
      "Iteration 2, loss = 0.14814594\n",
      "Iteration 3, loss = 0.12307402\n",
      "Iteration 4, loss = 0.11561360\n",
      "Iteration 5, loss = 0.10844919\n",
      "Iteration 6, loss = 0.09818531\n",
      "Iteration 7, loss = 0.09286425\n",
      "Iteration 8, loss = 0.09174718\n",
      "Iteration 9, loss = 0.08365321\n",
      "Iteration 10, loss = 0.07475305\n",
      "Iteration 11, loss = 0.07580126\n",
      "Iteration 12, loss = 0.06475330\n",
      "Iteration 13, loss = 0.06068905\n",
      "Iteration 14, loss = 0.05480120\n",
      "Iteration 15, loss = 0.04854284\n",
      "Iteration 16, loss = 0.04307016\n",
      "Iteration 17, loss = 0.04183962\n",
      "Iteration 18, loss = 0.03458280\n",
      "Iteration 19, loss = 0.03275869\n",
      "Iteration 20, loss = 0.02269426\n",
      "Iteration 21, loss = 0.02193569\n",
      "Iteration 22, loss = 0.01924063\n",
      "Iteration 23, loss = 0.02040244\n",
      "Iteration 24, loss = 0.02024982\n",
      "Iteration 25, loss = 0.01312514\n",
      "Iteration 26, loss = 0.01012394\n",
      "Iteration 27, loss = 0.01866983\n",
      "Iteration 28, loss = 0.01076514\n",
      "Iteration 29, loss = 0.00944013\n",
      "Iteration 30, loss = 0.00780270\n",
      "Iteration 31, loss = 0.00940498\n",
      "Iteration 32, loss = 0.01704888\n",
      "Iteration 33, loss = 0.02418475\n",
      "Iteration 34, loss = 0.00674455\n",
      "Iteration 35, loss = 0.00628117\n",
      "Iteration 36, loss = 0.00432508\n",
      "Iteration 37, loss = 0.01593152\n",
      "Iteration 38, loss = 0.00704642\n",
      "Iteration 39, loss = 0.00464060\n",
      "Iteration 40, loss = 0.01494672\n",
      "Iteration 41, loss = 0.01093876\n",
      "Iteration 42, loss = 0.00654107\n",
      "Iteration 43, loss = 0.00464063\n",
      "Iteration 44, loss = 0.00396651\n",
      "Iteration 45, loss = 0.00998459\n",
      "Iteration 46, loss = 0.00760307\n",
      "Iteration 47, loss = 0.02304812\n",
      "Iteration 48, loss = 0.00432963\n",
      "Iteration 49, loss = 0.00378553\n",
      "Iteration 50, loss = 0.00365701\n",
      "Iteration 51, loss = 0.00382028\n",
      "Iteration 52, loss = 0.00447770\n",
      "Iteration 53, loss = 0.02255238\n",
      "Iteration 54, loss = 0.00650371\n",
      "Iteration 55, loss = 0.00760812\n",
      "Iteration 56, loss = 0.00365997\n",
      "Iteration 57, loss = 0.00374266\n",
      "Iteration 58, loss = 0.00367814\n",
      "Iteration 59, loss = 0.00397174\n",
      "Iteration 60, loss = 0.00387113\n",
      "Iteration 61, loss = 0.00385352\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Cross-validation scores: [0.95431287 0.95458699 0.95303363 0.95339912 0.95595358]\n",
      "Average CV accuracy: 0.9542572359937432\n"
     ]
    }
   ],
   "source": [
    "#CROSS FOLD VALIDATION, DELETE IF NECESSARY\n",
    "\n",
    "# Initialize KFold with the desired number of folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(mlp_model, dense_tfidf_with_linguistic, dense_labels, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average CV accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.35462215\n",
      "Iteration 2, loss = 0.14054913\n",
      "Iteration 3, loss = 0.12020714\n",
      "Iteration 4, loss = 0.11031493\n",
      "Iteration 5, loss = 0.10679876\n",
      "Iteration 6, loss = 0.10506259\n",
      "Iteration 7, loss = 0.09704173\n",
      "Iteration 8, loss = 0.09375698\n",
      "Iteration 9, loss = 0.08575828\n",
      "Iteration 10, loss = 0.08181649\n",
      "Iteration 11, loss = 0.07909204\n",
      "Iteration 12, loss = 0.07542844\n",
      "Iteration 13, loss = 0.06773307\n",
      "Iteration 14, loss = 0.06388863\n",
      "Iteration 15, loss = 0.05607777\n",
      "Iteration 16, loss = 0.05136024\n",
      "Iteration 17, loss = 0.05091632\n",
      "Iteration 18, loss = 0.04646780\n",
      "Iteration 19, loss = 0.04145968\n",
      "Iteration 20, loss = 0.03412930\n",
      "Iteration 21, loss = 0.03123033\n",
      "Iteration 22, loss = 0.02836675\n",
      "Iteration 23, loss = 0.03000259\n",
      "Iteration 24, loss = 0.02396667\n",
      "Iteration 25, loss = 0.01882743\n",
      "Iteration 26, loss = 0.01699410\n",
      "Iteration 27, loss = 0.01711680\n",
      "Iteration 28, loss = 0.01429609\n",
      "Iteration 29, loss = 0.01167754\n",
      "Iteration 30, loss = 0.01258848\n",
      "Iteration 31, loss = 0.01138063\n",
      "Iteration 32, loss = 0.01611117\n",
      "Iteration 33, loss = 0.02124078\n",
      "Iteration 34, loss = 0.01009130\n",
      "Iteration 35, loss = 0.00966446\n",
      "Iteration 36, loss = 0.00631661\n",
      "Iteration 37, loss = 0.01557316\n",
      "Iteration 38, loss = 0.00749180\n",
      "Iteration 39, loss = 0.00757083\n",
      "Iteration 40, loss = 0.04399491\n",
      "Iteration 41, loss = 0.01045272\n",
      "Iteration 42, loss = 0.00726559\n",
      "Iteration 43, loss = 0.00665571\n",
      "Iteration 44, loss = 0.00606131\n",
      "Iteration 45, loss = 0.00610014\n",
      "Iteration 46, loss = 0.01548787\n",
      "Iteration 47, loss = 0.00607350\n",
      "Iteration 48, loss = 0.01215760\n",
      "Iteration 49, loss = 0.01044630\n",
      "Iteration 50, loss = 0.00932831\n",
      "Iteration 51, loss = 0.01033754\n",
      "Iteration 52, loss = 0.00764529\n",
      "Iteration 53, loss = 0.00554285\n",
      "Iteration 54, loss = 0.00454126\n",
      "Iteration 55, loss = 0.00863988\n",
      "Iteration 56, loss = 0.01407201\n",
      "Iteration 57, loss = 0.00536859\n",
      "Iteration 58, loss = 0.00473524\n",
      "Iteration 59, loss = 0.00544760\n",
      "Iteration 60, loss = 0.01760951\n",
      "Iteration 61, loss = 0.00552843\n",
      "Iteration 62, loss = 0.00457365\n",
      "Iteration 63, loss = 0.00412290\n",
      "Iteration 64, loss = 0.02245027\n",
      "Iteration 65, loss = 0.00680813\n",
      "Iteration 66, loss = 0.00832797\n",
      "Iteration 67, loss = 0.01235582\n",
      "Iteration 68, loss = 0.00582078\n",
      "Iteration 69, loss = 0.00485369\n",
      "Iteration 70, loss = 0.00542069\n",
      "Iteration 71, loss = 0.01058380\n",
      "Iteration 72, loss = 0.00452626\n",
      "Iteration 73, loss = 0.00448064\n",
      "Iteration 74, loss = 0.00440792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(600, 10), learning_rate=&#x27;adaptive&#x27;,\n",
       "              max_iter=300, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(600, 10), learning_rate=&#x27;adaptive&#x27;,\n",
       "              max_iter=300, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(600, 10), learning_rate='adaptive',\n",
       "              max_iter=300, verbose=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(dense_tfidf_with_linguistic, dense_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9541193882585101\n"
     ]
    }
   ],
   "source": [
    "text_test_preprocessed = text_test.apply(preprocess_text)\n",
    "test_tfidf_matrix = tfidf_vectorizer.transform(text_test_preprocessed)\n",
    "dense_test_tfidf_matrix = svd.transform(test_tfidf_matrix)\n",
    "dense_test_tfidf_with_linguistic = hstack([dense_test_tfidf_matrix, csr_matrix(test_linguistic_features)])\n",
    "test_labels = test_data['label'].values\n",
    "\n",
    "test_predictions = mlp_model.predict(dense_test_tfidf_with_linguistic)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3420\n",
      "           1       0.96      0.93      0.95      2661\n",
      "\n",
      "    accuracy                           0.95      6081\n",
      "   macro avg       0.96      0.95      0.95      6081\n",
      "weighted avg       0.95      0.95      0.95      6081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(test_labels, test_predictions)\n",
    "print(report)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlp_model_tfidf.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(mlp_model, 'mlp_model_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6081\n"
     ]
    }
   ],
   "source": [
    "print(lengthTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5802.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy*lengthTestData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
