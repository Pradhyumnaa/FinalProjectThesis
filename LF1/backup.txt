#Tokenizer for LIWC
def tokenize(text):
    for match in re.finditer(r'\w+', text, re.UNICODE):
        yield match.group(0)
parse, category_names = liwc.load_token_parser('LIWC2007_English100131.dic')
import string

def preprocess_text(text):
    # Remove punctuation
    translator = str.maketrans('', '', string.punctuation)
    text = text.translate(translator)

    # Remove excess whitespaces
    text = ' '.join(text.split())

    return text

# Example usage:
text_with_punctuation = "This is an example sentence with,            punctuation!!! !@!@! !?@?!@?! 12131 "
preprocessed_text = preprocess_text(text_with_punctuation)

print(f"Original text: {text_with_punctuation}")
print(f"Preprocessed text: {preprocessed_text}")

word_count = len(preprocessed_text.split())
print(word_count)
import re
import string

def preprocess_text(text):
    # Remove punctuation
    translator = str.maketrans('', '', string.punctuation)
    text = text.translate(translator)

    # Remove numbers
    text = re.sub(r'\b\d+\b', '', text)

    # Remove excess whitespaces
    text = ' '.join(text.split())

    return text

# Example usage:
text_with_punctuation = "This is an example sentence with,            punctuation!!! !@!@! !?@?!@?! 12131 "
preprocessed_text = preprocess_text(text_with_punctuation)

print(f"Original text: {text_with_punctuation}")
print(f"Preprocessed text: {preprocessed_text}")

word_count = len(preprocessed_text.split())
print(word_count)

























# Function to calculate Words per Sentence
def words_per_sentence(text):
    doc = nlp(text)
    sentences = [sent.text for sent in doc.sents]
    word_counts = [len(sent.split()) for sent in sentences]
    return sum(word_counts) / len(sentences) if len(sentences) > 0 else 0
# Function to calculate Percentage of Questions
def percentage_questions(text):
    doc = nlp(text)
    total_sentences = len(list(doc.sents))
    question_sentences = [sent.text for sent in doc.sents if '?' in sent.text]
    return (len(question_sentences) / total_sentences) * 100 if total_sentences > 0 else 0
# Function to calculate Percentage of First Person Singular
def percentage_first_person_singular(text):
    doc = nlp(text)
    total_words = len(doc)
    
    # List of first person singular pronouns
    first_person_singular_words = ["i", "me", "my", "mine"]
    
    # Count occurrences of first person singular pronouns
    first_person_singular_count = sum(1 for token in doc if token.lower_ in first_person_singular_words)
    
    return (first_person_singular_count / total_words) * 100 if total_words > 0 else 0

# Function to calculate Percentage of Second Person
def percentage_second_person(text):
    doc = nlp(text)
    total_words = len(doc)
    
    # List of first person singular pronouns
    second_person_words = ["you", "your", "yours", "yourself"]
    
    # Count occurrences of first person singular pronouns
    second_person_words_count = sum(1 for token in doc if token.lower_ in second_person_words)
    
    return (second_person_words_count / total_words) * 100 if total_words > 0 else 0

# Function to calculate Percentage of Third Person
def percentage_third_person(text):
    doc = nlp(text)
    total_words = len(doc)
    
    # List of first person singular pronouns
    third_person_words = ["he", "him", "his", "she", "her", "hers", "it", "its", "they", "them", "their", "theirs"]
    
    # Count occurrences of first person singular pronouns
    third_person_words_count = sum(1 for token in doc if token.lower_ in third_person_words)
    
    return (third_person_words_count / total_words) * 100 if total_words > 0 else 0





# Function to calculate Negations
def percentage_negations(text):
    text_tokens = tokenize(text)
    token_counts = Counter(category for token in text_tokens for category in parse(token))
    return(token_counts['negate'])
# Function to calculate Exclusive Words
def percentage_exclusive(text):
    text_tokens = tokenize(text)
    token_counts = Counter(category for token in text_tokens for category in parse(token))
    return(token_counts['excl'])
# Function to calculate Causation Words
def percentage_causation(text):
    text_tokens = tokenize(text)
    token_counts = Counter(category for token in text_tokens for category in parse(token))
    return(token_counts['cause'])
# Function to calculate Causation Words
def percentage_senses(text):
    text_tokens = tokenize(text)
    token_counts = Counter(category for token in text_tokens for category in parse(token))
    return(token_counts['percept'] + token_counts['see'] + token_counts['hear'] + token_counts['feel'])    




















# Function to calculate linguistic features
def calculate_linguistic_features(text):
    doc = nlp(text)
    total_words = len(doc)
    total_sentences = len(list(doc.sents))

    # List of first person singular pronouns
    first_person_singular_words = ["i", "me", "my", "mine"]

    # List of second person pronouns
    second_person_words = ["you", "your", "yours", "yourself"]

    # List of third person pronouns
    third_person_words = ["he", "him", "his", "himself", "she", "her", "hers", "herself", "it", "its", "itself", "they", "them", "their", "theirs", "themselves"]

    # Count occurrences of pronouns
    first_person_singular_count = sum(1 for token in doc if token.lower_ in first_person_singular_words)
    second_person_count = sum(1 for token in doc if token.lower_ in second_person_words)
    third_person_count = sum(1 for token in doc if token.lower_ in third_person_words)

    # Count occurrences of negations, exclusive words, causation, and senses using LIWC dictionary
    text_tokens = tokenize(text)
    token_counts = Counter(category for token in text_tokens for category in parse(token))
    negation_count = token_counts['negate']
    exclusive_count = token_counts['excl']
    causation_count = token_counts['cause']
    senses_count = token_counts['percept'] + token_counts['see'] + token_counts['hear'] + token_counts['feel']

    return {
        'Words_per_Sentence': total_words / total_sentences if total_sentences > 0 else 0,
        'Percentage_Questions': (len([sent.text for sent in doc.sents if '?' in sent.text]) / total_sentences) * 100 if total_sentences > 0 else 0,
        'Percentage_First_Person_Singular': (first_person_singular_count / total_words) * 100 if total_words > 0 else 0,
        'Percentage_Second_Person': (second_person_count / total_words) * 100 if total_words > 0 else 0,
        'Percentage_Third_Person': (third_person_count / total_words) * 100 if total_words > 0 else 0,
        'Percentage_Negation': negation_count,
        'Percentage_Exclusive': exclusive_count,
        'Percentage_Causation': causation_count,
        'Percentage_Sense': senses_count
    }    